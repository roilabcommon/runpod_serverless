#!/bin/bash
# Docker ë¹Œë“œ ë° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# Network Volume ì§€ì› 3ê°€ì§€ ì „ëµ: volume-only, docker-embedded, hybrid

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¤‘ë‹¨

# ê¸°ë³¸ê°’
DOCKER_USERNAME="${DOCKER_USERNAME:-your-username}"
IMAGE_NAME="runpod-tts-handler"
VERSION="latest"
STRATEGY="hybrid"
NO_PUSH=false
HELP=false

# ë„ì›€ë§ í•¨ìˆ˜
show_help() {
    cat << EOF
Usage: $0 [OPTIONS]

Docker ë¹Œë“œ ë° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ - RunPod Network Volume ì§€ì›

OPTIONS:
    --strategy <type>           ë°°í¬ ì „ëµ ì„ íƒ (ê¸°ë³¸ê°’: hybrid)
                                  volume-only: Network Volumeë§Œ ì‚¬ìš© (ì´ë¯¸ì§€ ~5-7GB)
                                  docker-embedded: Dockerì— ëª¨ë¸ í¬í•¨ (ì´ë¯¸ì§€ ~20-25GB)
                                  hybrid: Docker + Volume í˜¼í•© (ê¶Œì¥, ì´ë¯¸ì§€ ~20-25GB)

    --skip-models               --strategy volume-onlyì˜ ë‹¨ì¶•í‚¤

    --docker-username <name>    Docker Hub ì‚¬ìš©ìëª… (ê¸°ë³¸ê°’: $DOCKER_USERNAME)

    --version <tag>             ì´ë¯¸ì§€ ë²„ì „ íƒœê·¸ (ê¸°ë³¸ê°’: latest)

    --no-push                   Docker Hub í‘¸ì‹œ ìŠ¤í‚µ

    --help                      ì´ ë„ì›€ë§ í‘œì‹œ

EXAMPLES:
    # Volume-Only ì „ëµ (ê°œë°œìš©, ì‘ì€ ì´ë¯¸ì§€)
    $0 --strategy volume-only --docker-username myuser

    # Docker-Embedded ì „ëµ (ì¦‰ì‹œ ì‹œì‘)
    $0 --strategy docker-embedded --docker-username myuser

    # Hybrid ì „ëµ (í”„ë¡œë•ì…˜ ê¶Œì¥)
    $0 --strategy hybrid --docker-username myuser --version v1.0.0

ì „ëµ ë¹„êµ:
    Volume-Only: ì´ë¯¸ì§€ ì‘ìŒ, ì²« ì‹œì‘ ëŠë¦¼ (15-30ë¶„), ì´í›„ ë¹ ë¦„
    Docker-Embedded: ì´ë¯¸ì§€ í¼, í•­ìƒ ì¦‰ì‹œ ì‹œì‘
    Hybrid: ì´ë¯¸ì§€ í¼, ì²« ì‹œì‘ ì¤‘ê°„ ì†ë„ (5-10ë¶„), ì´í›„ ë¹ ë¦„

ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
}

# íŒŒë¼ë¯¸í„° íŒŒì‹±
while [[ $# -gt 0 ]]; do
    case $1 in
        --strategy)
            STRATEGY="$2"
            if [[ ! "$STRATEGY" =~ ^(volume-only|docker-embedded|hybrid)$ ]]; then
                echo "âŒ Error: Invalid strategy '$STRATEGY'. Must be one of: volume-only, docker-embedded, hybrid"
                exit 1
            fi
            shift 2
            ;;
        --skip-models)
            STRATEGY="volume-only"
            shift
            ;;
        --docker-username)
            DOCKER_USERNAME="$2"
            shift 2
            ;;
        --version)
            VERSION="$2"
            shift 2
            ;;
        --no-push)
            NO_PUSH=true
            shift
            ;;
        --help)
            show_help
            exit 0
            ;;
        *)
            echo "âŒ Unknown option: $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
if [[ "$DOCKER_USERNAME" == "your-username" ]]; then
    echo "âš ï¸  Warning: Using default Docker username 'your-username'"
    echo "   Set DOCKER_USERNAME environment variable or use --docker-username flag"
    echo ""
fi

FULL_IMAGE="$DOCKER_USERNAME/$IMAGE_NAME:$VERSION"

# ì „ëµë³„ ë¹Œë“œ ì¸ì ì„¤ì •
case $STRATEGY in
    volume-only)
        SKIP_MODEL_DOWNLOAD="true"
        EXPECTED_SIZE="~5-7GB"
        ;;
    docker-embedded)
        SKIP_MODEL_DOWNLOAD="false"
        EXPECTED_SIZE="~20-25GB"
        ;;
    hybrid)
        SKIP_MODEL_DOWNLOAD="false"
        EXPECTED_SIZE="~20-25GB"
        ;;
esac

echo "===================================="
echo "Docker Build & Deploy Script"
echo "===================================="
echo "Strategy:        $STRATEGY"
echo "Image:           $FULL_IMAGE"
echo "Skip Models:     $SKIP_MODEL_DOWNLOAD"
echo "Expected Size:   $EXPECTED_SIZE"
echo ""

# 1. Docker ë¹Œë“œ
echo "ğŸ“¦ Building Docker image..."
echo "   This may take 15-45 minutes depending on strategy..."
echo ""

docker build \
    --build-arg SKIP_MODEL_DOWNLOAD=$SKIP_MODEL_DOWNLOAD \
    -t $IMAGE_NAME:$VERSION \
    .

if [ $? -ne 0 ]; then
    echo "âŒ Build failed!"
    exit 1
fi

echo ""
echo "âœ… Build complete!"
echo ""

# ì´ë¯¸ì§€ í¬ê¸° í‘œì‹œ
echo "ğŸ“Š Image size information:"
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | grep -E "REPOSITORY|$IMAGE_NAME"
echo ""

# ì‹¤ì œ í¬ê¸°ì™€ ì˜ˆìƒ í¬ê¸° ë¹„êµ
ACTUAL_SIZE=$(docker images --format "{{.Size}}" $IMAGE_NAME:$VERSION)
echo "   Expected: $EXPECTED_SIZE"
echo "   Actual:   $ACTUAL_SIZE"
echo ""

# 2. ì´ë¯¸ì§€ íƒœê·¸
echo "ğŸ·ï¸  Tagging image..."
docker tag $IMAGE_NAME:$VERSION $FULL_IMAGE
echo ""

# 3. Docker Hub í‘¸ì‹œ (ì„ íƒ)
if [ "$NO_PUSH" = false ]; then
    read -p "Push to Docker Hub? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "ğŸ“¤ Pushing to Docker Hub..."
        echo "   This may take 10-60 minutes depending on image size..."
        docker push $FULL_IMAGE
        echo "âœ… Push complete!"
    else
        echo "â­ï¸  Skipping push"
    fi
else
    echo "â­ï¸  Skipping push (--no-push flag)"
fi

echo ""
echo "===================================="
echo "âœ… Done!"
echo "===================================="
echo ""

# ì „ëµë³„ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
echo "Next steps for $STRATEGY strategy:"
echo ""

case $STRATEGY in
    volume-only)
        cat << EOF
1. Create a RunPod Network Volume:
   - Go to RunPod Console > Serverless > Storage
   - Create new volume: name=roi_ai_studio, size=50GB
   - Note the mount path: /runpod-volume

2. Deploy to RunPod:
   - Container Image: $FULL_IMAGE
   - Network Volume: roi_ai_studio
   - Container Disk: 15GB (ëª¨ë¸ ë¯¸í¬í•¨ìœ¼ë¡œ ì‘ê²Œ ì„¤ì •)
   - GPU: RTX 4090 or A100

3. First worker start:
   - Will download models from HuggingFace (15-30 minutes)
   - Subsequent workers will use cached models (fast)

4. Update .env with RUNPOD_ENDPOINT_ID

5. Test: python test_runpod_endpoint.py --text "Hello" --audio sample.wav --model spark

ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
        ;;
    docker-embedded)
        cat << EOF
1. Deploy to RunPod (Network Volume ì„ íƒì‚¬í•­):
   - Container Image: $FULL_IMAGE
   - Container Disk: 30GB (ëª¨ë¸ í¬í•¨ìœ¼ë¡œ í¬ê²Œ ì„¤ì •)
   - GPU: RTX 4090 or A100
   - Network Volume: (ì„ íƒì‚¬í•­)

2. Workers will start immediately (ëª¨ë¸ ì´ë¯¸ í¬í•¨ë¨)

3. Update .env with RUNPOD_ENDPOINT_ID

4. Test: python test_runpod_endpoint.py --text "Hello" --audio sample.wav --model spark

Note: Network Volumeì„ ì—°ê²°í•˜ë©´ í–¥í›„ volume-onlyë¡œ ì „í™˜ ê°€ëŠ¥
ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
        ;;
    hybrid)
        cat << EOF
1. Create a RunPod Network Volume:
   - Go to RunPod Console > Serverless > Storage
   - Create new volume: name=roi_ai_studio, size=50GB
   - Note the mount path: /runpod-volume

2. Deploy to RunPod:
   - Container Image: $FULL_IMAGE
   - Network Volume: roi_ai_studio (ë°˜ë“œì‹œ ì—°ê²°!)
   - Container Disk: 30GB
   - GPU: RTX 4090 or A100

3. First worker start:
   - Will copy models from Docker â†’ Volume (5-10 minutes)
   - Subsequent workers will use volume models (fast)

4. Update .env with RUNPOD_ENDPOINT_ID

5. Test: python test_runpod_endpoint.py --text "Hello" --audio sample.wav --model spark

ì´ ì „ëµì€ í”„ë¡œë•ì…˜ í™˜ê²½ì— ê¶Œì¥ë©ë‹ˆë‹¤.
ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
        ;;
esac

echo ""
