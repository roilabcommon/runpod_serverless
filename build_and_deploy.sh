#!/bin/bash
# Docker ë¹Œë“œ ë° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# Network Volume ì§€ì› 3ê°€ì§€ ì „ëµ: volume-only, docker-embedded, hybrid

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¤‘ë‹¨

# ê¸°ë³¸ê°’
DOCKER_USERNAME="${DOCKER_USERNAME:-your-username}"
IMAGE_NAME="runpod-tts-handler"
VERSION="latest"
STRATEGY="volume-only"
NO_PUSH=false
HELP=false

# RunPod ì„¤ì •
RUNPOD_API_KEY="${RUNPOD_API_KEY:-}"
RUNPOD_VOLUME_ID="${RUNPOD_VOLUME_ID:-6vof5bpccl}"

# ë„ì›€ë§ í•¨ìˆ˜
show_help() {
    cat << EOF
Usage: $0 [OPTIONS]

Docker ë¹Œë“œ ë° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ - RunPod Network Volume ì§€ì›

OPTIONS:
    --strategy <type>           ë°°í¬ ì „ëµ ì„ íƒ (ê¸°ë³¸ê°’: volume-only)
                                  volume-only: Network Volumeì—ì„œ ëª¨ë¸ ë¡œë“œ (ê¶Œì¥, ì´ë¯¸ì§€ ~5-7GB)
                                  docker-embedded: Dockerì— ëª¨ë¸ í¬í•¨ (ì´ë¯¸ì§€ ~20-25GB)
                                  hybrid: Docker + Volume í˜¼í•© (ì´ë¯¸ì§€ ~20-25GB)

    --skip-models               --strategy volume-onlyì˜ ë‹¨ì¶•í‚¤

    --docker-username <name>    Docker Hub ì‚¬ìš©ìëª… (ê¸°ë³¸ê°’: $DOCKER_USERNAME)

    --version <tag>             ì´ë¯¸ì§€ ë²„ì „ íƒœê·¸ (ê¸°ë³¸ê°’: latest)

    --no-push                   Docker Hub í‘¸ì‹œ ìŠ¤í‚µ

    --help                      ì´ ë„ì›€ë§ í‘œì‹œ

EXAMPLES:
    # Volume-Only ì „ëµ (ê°œë°œìš©, ì‘ì€ ì´ë¯¸ì§€)
    $0 --strategy volume-only --docker-username myuser

    # Docker-Embedded ì „ëµ (ì¦‰ì‹œ ì‹œì‘)
    $0 --strategy docker-embedded --docker-username myuser

    # Hybrid ì „ëµ (í”„ë¡œë•ì…˜ ê¶Œì¥)
    $0 --strategy hybrid --docker-username myuser --version v1.0.0

ì „ëµ ë¹„êµ:
    Volume-Only: ì´ë¯¸ì§€ ì‘ìŒ, ì²« ì‹œì‘ ëŠë¦¼ (15-30ë¶„), ì´í›„ ë¹ ë¦„
    Docker-Embedded: ì´ë¯¸ì§€ í¼, í•­ìƒ ì¦‰ì‹œ ì‹œì‘
    Hybrid: ì´ë¯¸ì§€ í¼, ì²« ì‹œì‘ ì¤‘ê°„ ì†ë„ (5-10ë¶„), ì´í›„ ë¹ ë¦„

ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
}

# íŒŒë¼ë¯¸í„° íŒŒì‹±
while [[ $# -gt 0 ]]; do
    case $1 in
        --strategy)
            STRATEGY="$2"
            if [[ ! "$STRATEGY" =~ ^(volume-only|docker-embedded|hybrid)$ ]]; then
                echo "âŒ Error: Invalid strategy '$STRATEGY'. Must be one of: volume-only, docker-embedded, hybrid"
                exit 1
            fi
            shift 2
            ;;
        --skip-models)
            STRATEGY="volume-only"
            shift
            ;;
        --docker-username)
            DOCKER_USERNAME="$2"
            shift 2
            ;;
        --version)
            VERSION="$2"
            shift 2
            ;;
        --no-push)
            NO_PUSH=true
            shift
            ;;
        --help)
            show_help
            exit 0
            ;;
        *)
            echo "âŒ Unknown option: $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
if [[ "$DOCKER_USERNAME" == "your-username" ]]; then
    echo "âš ï¸  Warning: Using default Docker username 'your-username'"
    echo "   Set DOCKER_USERNAME environment variable or use --docker-username flag"
    echo ""
fi

FULL_IMAGE="$DOCKER_USERNAME/$IMAGE_NAME:$VERSION"

# ì „ëµë³„ ë¹Œë“œ ì¸ì ì„¤ì •
case $STRATEGY in
    volume-only)
        SKIP_MODEL_DOWNLOAD="true"
        EXPECTED_SIZE="~5-7GB"
        ;;
    docker-embedded)
        SKIP_MODEL_DOWNLOAD="false"
        EXPECTED_SIZE="~20-25GB"
        ;;
    hybrid)
        SKIP_MODEL_DOWNLOAD="false"
        EXPECTED_SIZE="~20-25GB"
        ;;
esac

echo "===================================="
echo "Docker Build & Deploy Script"
echo "===================================="
echo "Strategy:        $STRATEGY"
echo "Image:           $FULL_IMAGE"
echo "Skip Models:     $SKIP_MODEL_DOWNLOAD"
echo "Expected Size:   $EXPECTED_SIZE"
echo ""

# 1. Docker ë¹Œë“œ
echo "ğŸ“¦ Building Docker image..."
echo "   This may take 15-45 minutes depending on strategy..."
echo ""

docker build \
    --build-arg SKIP_MODEL_DOWNLOAD=$SKIP_MODEL_DOWNLOAD \
    -t $IMAGE_NAME:$VERSION \
    .

if [ $? -ne 0 ]; then
    echo "âŒ Build failed!"
    exit 1
fi

echo ""
echo "âœ… Build complete!"
echo ""

# ì´ë¯¸ì§€ í¬ê¸° í‘œì‹œ
echo "ğŸ“Š Image size information:"
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | grep -E "REPOSITORY|$IMAGE_NAME"
echo ""

# ì‹¤ì œ í¬ê¸°ì™€ ì˜ˆìƒ í¬ê¸° ë¹„êµ
ACTUAL_SIZE=$(docker images --format "{{.Size}}" $IMAGE_NAME:$VERSION)
echo "   Expected: $EXPECTED_SIZE"
echo "   Actual:   $ACTUAL_SIZE"
echo ""

# 2. ì´ë¯¸ì§€ íƒœê·¸
echo "ğŸ·ï¸  Tagging image..."
docker tag $IMAGE_NAME:$VERSION $FULL_IMAGE
echo ""

# 3. Docker Hub í‘¸ì‹œ (ì„ íƒ)
if [ "$NO_PUSH" = false ]; then
    read -p "Push to Docker Hub? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "ğŸ“¤ Pushing to Docker Hub..."
        echo "   This may take 10-60 minutes depending on image size..."
        docker push $FULL_IMAGE
        echo "âœ… Push complete!"
    else
        echo "â­ï¸  Skipping push"
    fi
else
    echo "â­ï¸  Skipping push (--no-push flag)"
fi

echo ""
echo "===================================="
echo "âœ… Done!"
echo "===================================="
echo ""

# 4. RunPod Endpointì— Network Volume ì—°ê²°
if [[ "$STRATEGY" != "docker-embedded" ]]; then
    echo ""
    echo "ğŸ”— Attaching Network Volume to Endpoint..."

    # .envì—ì„œ API Key ë¡œë“œ
    if [ -z "$RUNPOD_API_KEY" ] && [ -f ".env" ]; then
        RUNPOD_API_KEY=$(grep -oP 'RUNPOD_API_KEY=\K.*' .env 2>/dev/null | tr -d '"' | tr -d "'")
    fi

    if [ -n "$RUNPOD_API_KEY" ]; then
        # í˜„ì¬ Endpoint ì¡°íšŒ
        ENDPOINTS=$(curl -s -X POST "https://api.runpod.io/graphql?api_key=$RUNPOD_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{"query": "query { myself { endpoints { id name networkVolumeId gpuIds templateId workersMin workersMax idleTimeout } } }"}')

        ENDPOINT_ID=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['id'] if eps else '')" 2>/dev/null)

        if [ -n "$ENDPOINT_ID" ]; then
            # Endpointì˜ í˜„ì¬ Volume í™•ì¸
            CURRENT_VOLUME=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0].get('networkVolumeId') or '')" 2>/dev/null)

            if [ "$CURRENT_VOLUME" = "$RUNPOD_VOLUME_ID" ]; then
                echo "   âœ… Volume already attached to endpoint $ENDPOINT_ID"
            else
                echo "   Endpoint: $ENDPOINT_ID"
                echo "   Volume:   $RUNPOD_VOLUME_ID"

                # Endpoint ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                EP_NAME=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['name'])" 2>/dev/null)
                EP_GPU=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['gpuIds'])" 2>/dev/null)
                EP_TMPL=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['templateId'])" 2>/dev/null)
                EP_MIN=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['workersMin'])" 2>/dev/null)
                EP_MAX=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['workersMax'])" 2>/dev/null)
                EP_IDLE=$(echo "$ENDPOINTS" | python -c "import sys,json; eps=json.load(sys.stdin)['data']['myself']['endpoints']; print(eps[0]['idleTimeout'])" 2>/dev/null)

                RESULT=$(curl -s -X POST "https://api.runpod.io/graphql?api_key=$RUNPOD_API_KEY" \
                    -H "Content-Type: application/json" \
                    -d "{\"query\": \"mutation { saveEndpoint(input: { id: \\\"$ENDPOINT_ID\\\", name: \\\"$EP_NAME\\\", gpuIds: \\\"$EP_GPU\\\", networkVolumeId: \\\"$RUNPOD_VOLUME_ID\\\", templateId: \\\"$EP_TMPL\\\", workersMin: $EP_MIN, workersMax: $EP_MAX, idleTimeout: $EP_IDLE }) { id networkVolumeId } }\"}")

                if echo "$RESULT" | grep -q "networkVolumeId"; then
                    echo "   âœ… Network Volume attached successfully!"
                else
                    echo "   âŒ Failed to attach volume: $RESULT"
                fi
            fi
        else
            echo "   âš ï¸  No endpoint found. Create one first, then re-run this script."
        fi
    else
        echo "   âš ï¸  RUNPOD_API_KEY not set. Set it in .env or environment to auto-attach volume."
    fi
fi

# ì „ëµë³„ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
echo ""
echo "Next steps for $STRATEGY strategy:"
echo ""

case $STRATEGY in
    volume-only)
        cat << EOF
1. Create a RunPod Network Volume:
   - Go to RunPod Console > Serverless > Storage
   - Create new volume: name=roi_ai_studio, size=50GB, region=EU-RO-1
   - Volume ID: 6vof5bpccl (ì´ë¯¸ ìƒì„±ë¨)
   - Mount path: /runpod-volume

2. Deploy to RunPod:
   - Container Image: $FULL_IMAGE
   - Network Volume: roi_ai_studio
   - Container Disk: 15GB (ëª¨ë¸ ë¯¸í¬í•¨ìœ¼ë¡œ ì‘ê²Œ ì„¤ì •)
   - GPU: RTX 4090 or A100

3. First worker start:
   - Will download models from HuggingFace (15-30 minutes)
   - Subsequent workers will use cached models (fast)

4. Update .env with RUNPOD_ENDPOINT_ID

5. Test: python test_runpod_endpoint.py --text "Hello" --audio sample.wav --model spark

ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
        ;;
    docker-embedded)
        cat << EOF
1. Deploy to RunPod (Network Volume ì„ íƒì‚¬í•­):
   - Container Image: $FULL_IMAGE
   - Container Disk: 30GB (ëª¨ë¸ í¬í•¨ìœ¼ë¡œ í¬ê²Œ ì„¤ì •)
   - GPU: RTX 4090 or A100
   - Network Volume: (ì„ íƒì‚¬í•­)

2. Workers will start immediately (ëª¨ë¸ ì´ë¯¸ í¬í•¨ë¨)

3. Update .env with RUNPOD_ENDPOINT_ID

4. Test: python test_runpod_endpoint.py --text "Hello" --audio sample.wav --model spark

Note: Network Volumeì„ ì—°ê²°í•˜ë©´ í–¥í›„ volume-onlyë¡œ ì „í™˜ ê°€ëŠ¥
ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
        ;;
    hybrid)
        cat << EOF
1. Create a RunPod Network Volume:
   - Go to RunPod Console > Serverless > Storage
   - Create new volume: name=roi_ai_studio, size=50GB, region=EU-RO-1
   - Volume ID: 6vof5bpccl (ì´ë¯¸ ìƒì„±ë¨)
   - Mount path: /runpod-volume

2. Deploy to RunPod:
   - Container Image: $FULL_IMAGE
   - Network Volume: roi_ai_studio (ë°˜ë“œì‹œ ì—°ê²°!)
   - Container Disk: 30GB
   - GPU: RTX 4090 or A100

3. First worker start:
   - Will copy models from Docker â†’ Volume (5-10 minutes)
   - Subsequent workers will use volume models (fast)

4. Update .env with RUNPOD_ENDPOINT_ID

5. Test: python test_runpod_endpoint.py --text "Hello" --audio sample.wav --model spark

ì´ ì „ëµì€ í”„ë¡œë•ì…˜ í™˜ê²½ì— ê¶Œì¥ë©ë‹ˆë‹¤.
ìì„¸í•œ ì •ë³´: NETWORK_STORAGE_GUIDE.md ì°¸ê³ 
EOF
        ;;
esac

echo ""
